# task2_ml_model.py
"""
Task 2: Machine Learning Model
- Load processed dataset (from Task 1) or use iris dataset
- Train DecisionTreeClassifier and LogisticRegression
- Cross-validate and compare
- Save best model with joblib
"""

import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import matplotlib.pyplot as plt

def load_data():
    if os.path.exists("titanic_processed.csv"):
        df = pd.read_csv("titanic_processed.csv")
        if "survived" not in df.columns:
            raise ValueError("Processed dataset does not contain 'survived' target column.")
        X = df.drop(columns=["survived"])
        y = df["survived"]
    else:
        # Fallback to iris for demonstration
        from sklearn.datasets import load_iris
        iris = load_iris()
        X = pd.DataFrame(iris.data, columns=iris.feature_names)
        y = pd.Series(iris.target, name="target")
    return X, y

def train_and_evaluate(X, y):
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y if len(np.unique(y))>1 else None)

    # Models to compare
    dt = DecisionTreeClassifier(random_state=42)
    lr = LogisticRegression(max_iter=1000, solver="liblinear")  # liblinear good for small datasets

    # Cross-validate
    for name, model in [("Decision Tree", dt), ("Logistic Regression", lr)]:
        scores = cross_val_score(model, X_train, y_train, cv=5, scoring="accuracy")
        print(f"{name} CV accuracy: mean={scores.mean():.4f}, std={scores.std():.4f}")

    # Grid search for best Decision Tree depth
    param_grid = {"max_depth": [2, 3, 4, 5, 6, None], "min_samples_leaf":[1,2,4]}
    grid_dt = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=5, scoring="accuracy")
    grid_dt.fit(X_train, y_train)
    best_dt = grid_dt.best_estimator_
    print("Best DT params:", grid_dt.best_params_)

    # Train logistic
    lr.fit(X_train, y_train)

    # Evaluate on test
    models = {"DecisionTree": best_dt, "LogisticRegression": lr}
    results = {}
    for name, model in models.items():
        preds = model.predict(X_test)
        acc = accuracy_score(y_test, preds)
        print(f"\n{name} Test accuracy: {acc:.4f}")
        print("Classification report:")
        print(classification_report(y_test, preds))
        print("Confusion matrix:")
        print(confusion_matrix(y_test, preds))
        results[name] = (acc, model)

    # Save the best model
    best_name = max(results.items(), key=lambda kv: kv[1][0])[0]
    best_model = results[best_name][1]
    joblib.dump(best_model, f"{best_name}_best_model.joblib")
    print(f"Saved best model: {best_name}_best_model.joblib")

    # If DecisionTree, plot
    if isinstance(best_model, DecisionTreeClassifier):
        plt.figure(figsize=(12,6))
        plot_tree(best_model, filled=True, feature_names=X.columns, class_names=[str(c) for c in np.unique(y).tolist()])
        plt.title("Decision Tree")
        plt.tight_layout()
        plt.savefig("decision_tree_plot.png")
        print("Saved decision_tree_plot.png")

def main():
    X, y = load_data()
    train_and_evaluate(X, y)

if __name__ == "__main__":
    main()
